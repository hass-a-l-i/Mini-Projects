import matplotlib.pyplot as plt
import pandas
from collections import Counter
import itertools

# data base of words opened
words = open("words.txt", "r")
raw_words = words.readlines()

clean = map(lambda s: s.strip(), raw_words)

# map words into a list
clean = list(clean)


# define function for splitting string into list of characters


def split(word):
    return [char for char in word]


yo = []
# split the list of words into list of lists of characters
for x in clean:
    zo = split(x)
    data = yo.append(zo)

# list comprehension to concatenate list of lists
data = [item for sublist in yo for item in sublist]


# histogram for character vs frequency
def histdistr():
    letter_counts = Counter(data)
    df = pandas.DataFrame.from_dict(letter_counts, orient='index')
    df.plot(kind='bar')
    plt.show()


# create dictionary to count no characters in data set
count = {}
for s in data:
    if s in count:
        count[s] += 1
    else:
        count[s] = 1


dj = []
jj = []

# use keys for each entry in count dictionary to convert the dictionary into two lists, as long as len(char) > thresh
thresh = 0
for key in count:
    if count[key] > thresh:
        print(key, count[key])
        dj.append(key)
        jj.append(count[key])

# make list of tuples for (character, character frequency)
fl = list(zip(dj, jj))

# convert list of characters back into string
def convert(s):
    new = ""

    for x in s:
        new += x

    return new

dd = convert(dj)

# go through every permutation of 5 letter words from pool of characs above defined thresh
we = list(itertools.permutations(dd, 5))

iw = []

# convert the permutations of chars into strings
for item in we:
    item = convert(item)
    iw.append(item)

# find actual words from random permutations using original list of words (overlap)
ur = list(set(iw) & set(clean))

# use frequency of each character above thresh found earlier to make variables from each character (DID NOT WORK USED OTHER METHOD)
#for item in fl:
#    exec("%s = %d" % (item[0], item[1]))

# make list of chars from words found in overlap
kq = [list(item) for item in ur]

yt = len(kq)
cf = list(range(0, yt - 1))

tj = []

# loop through list of tuples to find any matches to the list of chars found earlier, if match then sum up the second half of tuple to find cumulative frequency
for i in cf:
    qt = kq[i]
    # print(qt)

    kl = []

    for item in fl:
        if item[0] in qt:
            kl.append(item[1])
    # print(kl)
    # print(sum(kl))
    tj.append(sum(kl))

# make list of tuples from most likely words and cumulative frequencies
gh = list(zip(ur, tj))

# sort list to go in descending order, finding best to worst guess
ghj = sorted(gh, key=lambda x: x[1], reverse=True)

# permutations containing same letter redundant soe these removed with empty set filter
up = set()
opp = []
for a, b in ghj:
    if not b in up:
        up.add(b)
        opp.append((a, b))

print("wordbank =", clean)
# print(yo)
#print(count)
#print(dd)
#print(jj)
#print(dj)
#print(dd)
#print(iw)
#print(ur)
#print(fl)
#print(kq)
#print(gh)
# print(opp)

with open('final5.txt', 'w') as fp:
    fp.write('\n'.join('%s %s' % x for x in opp))